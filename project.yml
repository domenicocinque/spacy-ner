title: "Named Entity Recognition"
description: "Train a spaCy model to predict named entities in text"

# Variables that can be used in the commands below. 
vars:
  name: "ner_project"
  lang: "en"
  train: "train.txt"
  dev: "dev.txt"
  test: "test.txt"
  version: "0.0.1"
  # Set your GPU ID, -1 is CPU
  gpu_id: 0
  vectors_model: "en_core_web_md"

# These are the directories that the project needs. The project CLI will make
# sure that they always exist.
directories: ["assets", "corpus", "configs", "training", "scripts", "packages"]

# Assets that should be downloaded or available in the directory. We're shipping
# them with the project, so they won't have to be downloaded.
assets:
  - dest: "assets/train.txt"
    description: "Conll train data" 
  - dest: "assets/dev.txt"
    description: "Conll validation data"
  - dest: "assets/test.txt"
    description: "Conll test data"  

# Workflows are sequences of commands (see below) executed in order. 
# The following can be run with `weasel run all`. 
workflows:
  all:
    - download-data
    - download-model
    - convert
    - train
    - evaluate

# Single commands that can be run with `weasel run <command>`.
commands:
  - name: "download-data"
    help: "Pull the data from the remote storage"
    script:
      - "dvc pull"

  - name: "download-model"
    help: "Download a spaCy model with pretrained vectors"
    script:
      - "python -m spacy download ${vars.vectors_model}"

  - name: "convert"
    help: "Convert the data to spaCy's binary format"
    script:
      - "python -m spacy convert assets/${vars.train} corpus/ --converter conll -n 3"
      - "python -m spacy convert assets/${vars.dev} corpus/ --converter conll -n 3"
      - "python -m spacy convert assets/${vars.test} corpus/ --converter conll -n 3"
    deps:
      - "assets/${vars.train}"
      - "assets/${vars.dev}"
      - "assets/${vars.test}"
    outputs:
      - "corpus/train.spacy"
      - "corpus/dev.spacy"
      - "corpus/test.spacy"

  - name: "train"
    help: "Train the NER model"
    script:
      - "python -m spacy train configs/config.cfg --output training/ --paths.train corpus/train.spacy --paths.dev corpus/dev.spacy --training.eval_frequency 10 --training.patience 50 --gpu-id ${vars.gpu_id} --initialize.vectors ${vars.vectors_model} --components.tok2vec.model.embed.include_static_vectors true"
    deps:
      - "configs/config.cfg"
      - "corpus/train.spacy"
      - "corpus/dev.spacy"
    outputs:
      - "training/model-best"

  - name: "evaluate"
    help: "Evaluate the model and export metrics"
    script:
      - "python -m spacy evaluate training/model-best corpus/dev.spacy --output training/metrics.json"
    deps:
      - "corpus/dev.spacy"
      - "training/model-best"
    outputs:
      - "training/metrics.json"

  - name: visualize-model
    help: Visualize the model's output interactively using Streamlit
    script:
      - "streamlit run scripts/visualize_model.py training/model-best \"I saw Shaka Khan in London.\""
    deps:
      - "scripts/visualize_model.py"
      - "training/model-best"

  - name: package
    help: "Package the trained model as a pip package"
    script:
      - "python -m spacy package training/model-best packages --name ${vars.name} --version ${vars.version} --force"
    deps:
      - "training/model-best"
    outputs_no_cache:
      - "packages/${vars.lang}_${vars.name}-${vars.version}/dist/${vars.lang}_${vars.name}-${vars.version}.tar.gz"